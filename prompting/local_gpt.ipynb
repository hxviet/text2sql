{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCG_kJTAqqa4",
        "outputId": "b6ebd221-14d8-463c-8741-54c11d9df244"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-0.3.5-py3-none-manylinux1_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.4)\n",
            "Installing collected packages: gpt4all\n",
            "Successfully installed gpt4all-0.3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install gpt4all"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt4all\n",
        "gptj = gpt4all.GPT4All(\"ggml-gpt4all-j-v1.3-groovy\")\n",
        "messages = [{\"role\": \"user\", \"content\": \"Name 3 colors\"}]\n",
        "gptj.chat_completion(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2MeAeejq-bm",
        "outputId": "63e2ce0f-8052-4364-a300-64b9d703bee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.79G/3.79G [02:34<00:00, 24.4MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded at:  /root/.cache/gpt4all/ggml-gpt4all-j-v1.3-groovy.bin\n",
            "### Instruction: \n",
            "            The prompt below is a question to answer, a task to complete, or a conversation \n",
            "            to respond to; decide which and write an appropriate response.\n",
            "            \n",
            "### Prompt: \n",
            "Name 3 colors\n",
            "### Response:\n",
            " \n",
            "Blue, Green and Orange\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'ggml-gpt4all-j-v1.3-groovy',\n",
              " 'usage': {'prompt_tokens': 239, 'completion_tokens': 24, 'total_tokens': 263},\n",
              " 'choices': [{'message': {'role': 'assistant',\n",
              "    'content': ' \\nBlue, Green and Orange'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"Generate a SQL query corresponding to the following question: How many students are there? Given that we have a database (student) with columns (student_id),(name),(class)\"}]"
      ],
      "metadata": {
        "id": "1fNzHwuJrR3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = gptj.chat_completion(messages)['choices'][0]['message']['content']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjBDEFo8scqw",
        "outputId": "8858915a-d604-4e67-d25a-f673b5448fa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: \n",
            "            The prompt below is a question to answer, a task to complete, or a conversation \n",
            "            to respond to; decide which and write an appropriate response.\n",
            "            \n",
            "### Prompt: \n",
            "Generate a SQL query corresponding to the following question: How many students are there? Given that we have a database (student) with columns (student_id),(name),(class)\n",
            "### Response:\n",
            " \n",
            "SELECT COUNT(*) FROM student;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KELn1rZsgPo",
        "outputId": "0d66e508-2fcd-4470-ba79-5683eb2012d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "SELECT COUNT(*) FROM student;\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem with this model: Implemented on CPU -> Generation speed is very slow (about 90 secs/300-character input)"
      ],
      "metadata": {
        "id": "6k75M570mFSp"
      }
    }
  ]
}